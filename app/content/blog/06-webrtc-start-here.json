{
  "title": "06 - WebRTC: start here",
  "tag": "General Concepts",
  "content": "In the past two years, teaching has been one of the secondary activities I have been involved in the most. \n\nIn a couple of ways. \n\nFirst, I started teaching web development fundamentals at the faculty where I graduated from. \n\nTechnically, this was not my first teaching experience, as I already have some-kind-of-degree in this direction, but it was still my first *official* experience.  \n\n<div style=\"display: flex; justify-content: center; align-items: center; flex-direction: column\">\n    <img src='/images/uploads/06_00.jpg' description='Teaching' >\n    <p style=\\\"margin-top:0px;font-size:12px;\\\">Photo by <a href='https://unsplash.com/@neonbrand'>Kenny Eliason</a></p>\n</div>\n\nAs a thoughtful person, you would probably think that doing something for the first time is challenging enough, right? \n\nWell, me too, but at the same time another opportunity came across - and I accepted it: here comes my second teaching *job* before I even started my first: a technical trainer position at Devmind, a local software development academy focusing on computer science fundamentals, Java & full-stack development. \n\nIncluding my main job as a full-time software engineer, I had to handle three jobs at (roughly) the same time.\n\nI have to admit that it was pretty tough on my [Backloggd playlist](https://backloggd.com/u/axbg/games/added/type:playing/), but it was very fruitful experience. I learned a lot, and it's something that I would like to do for a long time from now on.\n\nI'm not yet ready to call it my vocation, but, considering the context, it was an important achievement that I managed to handle my two newly acquired jobs pretty well if I were to trust the feedback I received from my students and supervisors. (hopefully, they were not just nice about it)\n\nSo I think it's fair to say that teaching is something that I do now, and it's something that I enjoy very much. \n\nConsidering everything that I just mentioned, it should come as no surprise that I think teaching stuff is a cool endeavor.\n\nThere's only one small downside to it: you have to talk a lot. \n\nI do come off as a talker, I know, it's not an issue for me, as I would rather say that I'm pretty good at it, but it can become very boring, very fast for the listeners, especially if it's a more in-depth subject. \n\nAs a solution, it's good to have some sort of presentation, be it PowerPoint or something else, so the audience will not become *too* bored too quickly. \n\nBut what do you do if you're facing something like this in 2025?\n\n<div style=\"display: flex; justify-content: center; align-items: center; flex-direction: column\">\n    <img src='/images/uploads/06_01.webp' description='VGA' >\n</div>\n\nResigning was my first thought as well, but there are a couple more sensible solutions to fix this issue, right?\n\nFor starters, you can buy an adapter for a couple of bucks, it's not that hard. Or you can just use Zoom as everybody else and call it a day. \n\nAnd, of course, there's also a not-so-reasonable solution which ended up being the one I chose: **build an app**.\n\nBut what qualities should this new app have? \n\nI didn't know exactly how I would build it, but I knew some mandatory features:\n- easy to build (so I can finish it before the semester ends)\n- easy to deploy (so I don't have to invest too much time for maintenance)\n- working on various clients (so every student can use it on their machine)\n- adaptable to all network conditions (because the network sucks - most of the time, for various reasons)\n\nThat's how I ended up reading more about WebRTC. \n(yes, this was just an introduction)\n\n<div style=\"display: flex; justify-content: center; align-items: center; flex-direction: column\">\n    <img src='/images/uploads/06_02.png' description='VGA' >\n</div>\n\nI was lucky enough to stumble upon [**the book**](https://webrtcforthecurious.com/) after a couple of minutes of searching around. \n\nBy **the book** I mean the WebRTC for Curious, probably the best way of grasping more about the internals of WebRTC, understanding where it came from and how it works without having too steep of a learning curve. \n\nShout out to the authors, who are also some of the programmers who built what we know today as WebRTC. \n\nThis means that I have to thank them twice, and, if you ever talked to someone using a video chat app using just your browser, you probably should too. \n\nAt first, I wanted to understand what WebRTC is, because it was pretty hard to pin it down to a single thing, so I started a list that I continuously refined until I ended up with something. \n\nAccording to this very brief analysis, WebRTC turned out to be many things:\n- a free and open-source project that became a web standard\n- a collection of technologies used together to achieve real-time peer-to-peer (P2P) transmissions using UDP\n- a global standardization effort\n- a pragmatic approach that makes use of preexisting protocols\n- a secure-by-default way to exchange real-time media\n- a set of APIs that can be used to integrate real-time media exchange in web applications\n\nI'm still not 100% sure that I got everything right, but this should be a pretty comprehensive list. \n\nI really think that **the book** does a great job and, for a couple of reasons, I could end the article here, but, if you're interested, I would like to walk you through the way I explained to myself the core concepts that make WebRTC so awesome and so easy to use. \n\nIt could be a bit of a ride, so buckle up. \n\n<div style=\"display: flex; justify-content: center; align-items: center; flex-direction: column\">\n    <img src='/images/uploads/06_03.jpg' description='Touching hands' >\n    <p style=\\\"margin-top:0px;font-size:12px;\\\">Photo available on <a href='https://www.freepik.com/free-photo/hands-gently-touching-each-other_2111016.htm#fromView=keyword&page=1&position=2&uuid=b92cd659-cd23-48d4-b100-24975b99aab0&query=Touching+Hands'>Freepik</a></p>\n</div>\n\nThe underlying technologies, which represent the fabric of WebRTC, are used in a specific order to exchange real-time media between two clients.\n\nFor a connection to be established, each of these processes must succeed:\n1. Signaling\n  1. Media negotiation\n  2. Discovery\n2. Establishing a connection\n\nLet's take a closer look at each of them.\n\n### Signaling - finding each other\nWebRTC aims to establish a P2P connection between two participants. (we'll call them **peers**)\n\nAs in all P2P systems, before the connection can be established, a mechanism that allows the peers to find each other is required.\n\nFunny enough, even though it's the first step, **WebRTC does not cover signaling**: each implementer can choose how the peers will discover each other.\n\nThe most common approach is to use a *WebSocket* server that governs the initial discovery process.\n\n<br>\n\n#### data about data\nSignaling starts with an exchange between the peers: one of them will initiate the process by sending an **offer**, and, after reviewing the offer, the other one responds with an **answer**.\n\nThese objects, which are exchanged through the signaling server, contain all the information required for the peers to understand **what type of media will be streamed**.\n\nNo connection is established at the moment, but if the negotiation between the peers does not succeed, the process is dropped.\n\nThe *offer* and the *answer* are part of the *Session Description Protocol* (SDP) which is used internally by WebRTC.\n\n<br>\n\n#### a direct path\nThe peers know what media will be exchanged, but they are not connected yet.\n\nBesides the initial process, when a centralized \"meeting\" point is used, WebRTC aims to use P2P connections.\n\nThe main advantages are lower latency, lower infrastructure costs, and increased security, as no data is processed by any central server. \n\nThe advantages come with some caveats, as establishing a direct connection between two peers in a huge network like the Internet is not a trivial task.\n\nUnlike the more common client/server systems, where the server is directly accessible on the Internet, peers in P2P connections might not share the same network or have public IP addresses.\n\nIn such cases, *Network Address Translation (NAT)* is the key mechanism that enables connections.\n\nNAT mapping allows devices on a private network to communicate with other devices on the Internet by translating their private IP addresses into public IP addresses.\n\nNAT also makes it possible for external devices to connect to agents in a private network using an existing mapping.\n\n<br>\n\n#### the world is NATs\n\nNATs come in different flavors, and sometimes they can block peers from establishing a connection.\n\n<div style=\"display: flex; justify-content: center\">\n    <img src='/images/uploads/06_04.png' description='NAT' >\n</div>\n\nThe most important classification describes the mapping creation behaviors, where NATs can be:\n- Endpoint independent - once a mapping is created it can be reused\n- Address/Address and Port dependent mapping - a mapping is created for each connection, targeting a specific address or address and port\n\nThe same classification can be applied to mapping filtering behaviors.\n\n**For WebRTC to work using P2P, at least one of the peers should have an endpoint-independent mapping**\n\nIn case P2P connection is not possible, WebRTC can still function using a relay server. \n\n<br>\n\n#### who am I?\nThe details about the NAT are not known to the peers.\n\nWhile they can create NAT mappings by sending outbound requests, they are not aware of their own Internet-facing address.\n\nThis is where the Session Traversal Utilities for NAT **(STUN)** protocol comes into play.\n\nTo learn more about their external IP, each peer will connect to a STUN server and will receive information about the external IP mapping done by NAT.\n\n<div style=\"display: flex; justify-content: center; align-items: center; flex-direction: column\">\n    <img src='/images/uploads/06_05.png' description='STUN' >\n</div>\n\n<br>\n\n### Establishing a connection\n#### ICE, ICE, baby\nTo establish a connection, WebRTC uses the *Interactive Connectivity Establishment (ICE)* technology.\n\nICE uses the STUN answer, together with the local IP of the peer, to determine a list of possible addresses that can be used for connection.\n\nThe candidates are exchanged using the signaling server and ICE starts to group each local candidate with each remote candidate, obtaining multiple *candidate pairs*.\n\nICE tries to establish a connection between the members of each pair, and, based on connectivity and performance, selects a pair that becomes the *selected candidate pair* that will be used for the rest of the session.\n\nThe peers are now P2P connected, and they can start to exchange media respecting the *offers* that they agreed upon.\n\n<div style=\"display: flex; justify-content: center;\">\n  <i style=\"font-size: 5rem\">🔗</i>\n</div>\n\n<br>\n\n#### rely on relaying\nIf a direct connection cannot be established due to the restrictive nature of the NATs, a direct ICE connection will fail as well.\n\nIn this situation, ICE will use the Traversal Using Relays around NAT (TURN)* protocol to mediate the exchange through a *relay server*.\n\nUnlike the STUN server, which does not establish a permanent connection with the peers, the TURN server will receive traffic from each peer and will ensure the correct retransmission.\n\n**A robust WebRTC integration should always use TURN as a fallback mechanism**\n\n<div style=\"display: flex; justify-content: center; align-items: center; flex-direction: column\">\n    <img src='/images/uploads/06_06.png' description='TURN' >\n</div>\n\n<br>\n\n### enough talk, let's code the talk\n*(sorry for the bad pun)*\n\nWebRTC is a web-first standard, as the name implies.\n\nThe main implication of this fact is that all popular browsers offer native support for it through an API that resembles more common ones that you might already know. \n\n<br>\n\n#### capturing user media\n\nBefore exchanging media streams, a client should *capture* them.\n\nMost browsers support the standard *Media Capture and Streams API* (MediaStream API) which allows the capture of webcams, screens, device audio, and microphones.\n\n```javascript\n// captures webcam and microphone\nconst capturedUserStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true});\n// captures screen and audio device (currently supported only in Chrome for individual browser tabs)\nconst captureMediaStream = await navigator.mediaDevices.getDisplayMedia({ video: true, audio: true });\n```\n\nThe user will be prompted for consent for each captured stream.\n\nThe MediaStream API was developed together with the WebRTC API, so the captured media streams can seamlessly be used as sources in the live media exchange process.\n\nEach track can receive as a parameter an object representing the [*constraints*](https://developer.mozilla.org/en-US/docs/Web/API/MediaTrackConstraints) that should be applied.\n\n<br>\n\n#### peers and streams\n\nThe initiating client is ready to create a peer instance:\n```javascript\n// the configuration object is used to configure the ICE process\n// in a simple implementation, it just specifies which STUN/TURN servers to use\n//  in more complex implementations, the configuration object can define additional options: https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/RTCPeerConnection\nconst configuration = {'iceServers': [{'urls': ['stun:stun.l.google.com:19302', 'turn:TURN_IP:3478[user:password]']}]}\nconst peerConnection = new RTCPeerConnection(configuration);\n```\n\nBefore creating an offer, the peer instance should be instructed on how to handle upcoming connections.\n\nThe order in which these configurations are written is not important, as they will be triggered after the offer is sent.\n\nThe first thing could be to bind the captured user media stream to the peer instance:\n```javascript\ncapturedUserMedia.getTracks().forEach(track => {\n  // the type of each added track can be determined by the 'kind' property (e.g: video, audio)\n  // if the tracks are associated with a stream instance, WebRTC will handle them together\n  peerConnection.addTrack(track, capturedUserMedia);\n});\n```\n\nEach WebRTC interaction is handled in an event-like manner: each peer will do an action, while the other will specify, ahead of time, its behavior for each event.\n\nSo, the peer should be instructed what to do when it receives tracks from the remote peer:\n```javascript\npeerConnection.ontrack = (event) => {\n  // even though individual tracks are received, we are referencing to the stream\n  // this way, both video and audio tracks could be handled by the same HTML video element\n  videoElement.srcObject = event.streams[0];\n};\n```\n\nWhen the offer is created, WebRTC will start gathering ICE candidates and will send each one of them to the connecting peer through the signaling server:\n```javascript\npeerConnection.onicecandidate = (event) => {\n  if (event.candidate) {\n    // generic method that will rely on the signaling server\n    sendToSignalingServer(event.candidate)\n  }\n};\n```\n\nPeers are informed each time the state of the connection changes:\n```javascript\npeerConnection.onconnectionstatechange = () => {\n  switch (peerConnection.connectionState) {\n    case \"connected\":\n      //...\n    case \"disconnected\":\n      //...\n    case \"closed\":\n      //...\n    case \"failed\":\n      //...\n}};\n```\n\nNow the initiating peer is ready to create an offer and send it to the other peer through the signaling server:\n```javascript\nconst offer = await peerConnection.createOffer();\nawait peerConnection.setLocalDescription(offer);\n\nsendToSignalingServer(offer);\n```\n\n<br>\n\n#### accepting an offer\n\nWhen an offer is received, the receiver creates its own peer instance following a very similar set of steps, accepts the offer, and sends the answer back:\n```javascript\nwebSocket.on(\"receiving-offer\", async (payload) => {\n  const peerConnection = new RTCPeerConnection(configurations);\n\n  // ...\n  // setting up its event handlers\n  // ...\n\n  peerConnection.setRemoteDescription(payload.offer);\n\n  const answer = await peerConnection.createAnswer();\n  await peerConnection.setLocalDescription(answer);\n\n  sendToSignalingServer(answer);\n});\n```\n\n<br>\n\n#### breaking the ICE\n\nThe only thing that was not covered until now is handling remote ICE candidates.\n\nBesides gathering and sending its own ICE candidates to the signaling server, each peer should prepare to receive the ICE candidates of the opposite side:\n```javascript\nwebSocket.on(\"ice-candidate\", (payload) => {\n  peerConnection.addIceCandidate(new RTCIceCandidate(payload.candidate))\n    .then(() => console.log(\"Added ICE candidate from viewer\", payload.candidate))\n    .catch(error => console.error(\"Error adding ICE candidate:\", error));\n});\n```\n\nStarting with the first candidate that arrives, WebRTC creates and tests all the possible **pairs**.\n\nOnce the best pair is found, the connection state is promoted to **connected** and the negotiated streams are exchanged P2P.\n\n<div style=\"display: flex; justify-content: center\">\n  <p style=\"font-size: 5rem\">🎆</p>\n</div>\n\n<br>\n\n#### renegotiation\nIt happens frequently for peers to want to remove some media tracks or add new ones after the connection is established.\n\nFor soft removal, a solution is to disable it, having the option to enable it again later:\n```javascript\nif (captureUserMedia && capturedUserMedia.getVideoTracks().length > 0) {\n  capturedUserMedia.getVideoTracks()[0].enabled = false;\n}\n```\n\nAdding or removing tracks triggers the renegotiation process which should establish a new pair of offer/answer:\n```javascript\npeerConnection.onnegotiationneeded = () => {\n  const offer = await peerConnection.createOffer();\n  // make sure to reuse the existing peer on both ends\n  await peerConnection.setLocalDescription(offer);\n  sendToSignalingServer(offer);\n}\n// modify the media tracks associated with the peerConnection to trigger the renegotiation\n```\n\nBy default, the ICE connection will not be modified, but a peer can request it by toggling the iceRestart* parameter.\n\nOn the receiving end, the peer should also be reused: \n```javascript\nwebSocket.on(\"receiving-offer\", async (payload) => {\n  if (peerConnection) {\n    peerConnection.setRemoteDescription(payload.offer);\n\n    const answer = await peerConnection.createAnswer();\n    await peerConnection.setLocalDescription(answer);\n\n    sendToSignalingServer(answer);\n  } else {\n    peerConnection = new RTCPeerConnection(configurations);\n    // the rest of the configuration discussed above\n  }\n}\n```\n\nRenegotiation can be triggered by both ends and when both ends emit an offer at the same time, the ICE state machine could be upset.\n\nThis is known as the **glare problem** and there are [ways to handle it beautifully](https://blog.mozilla.org/webrtc/perfect-negotiation-in-webrtc/)\n\n\nAnd that's it - at least for the most part. \n\nBesides knowing how to create a connection between two (or more) peers you should now be able to explain how WebRTC works using simple terms, like, hopefully, I managed to do. \n\nI would like to talk just a bit more, presenting some miscellaneous topics related to WebRTC that might be useful if you're trying to implement more complex scenarios. \n\n<br>\n\n### The downside of P2P\n\nP2P has a lot of benefits, but one important downside: it does not scale well.\n\nThe previous example could handle a small group of people, but after a dozen, the number of parallel connections becomes unmanageable.\n\nEach user must handle n-1 connections, and the total number of connections can be computed as n * (n - 1) / 2.\n\nThe traditional, P2P topologies are fairly intuitive, but all of them suffer during scaling, sooner or later: \n\n<div style=\"display: flex; justify-content: center;\">\n\t<div>\n\t    <img src='/images/uploads/06_07.png' description='P2P one-to-one'>\n\t    <p style=\\\"margin-top:0px;font-size:12px;\\\">One-to-One</p>\n\t</div>\n\t<div>\n\t    <img src='/images/uploads/06_08.png' description='P2P full mesh'>\n\t    <p style=\\\"margin-top:0px;font-size:12px;\\\">Full Mesh</p>\n\t</div>\n\t<div>\n\t    <img src='/images/uploads/06_09.png' description='P2P hybrid mesh'>\n\t    <p style=\\\"margin-top:0px;font-size:12px;\\\">Hybrid Mesh</p>\n\t</div>\n</div>\n\nThis is the reason why, to build robust real-time media applications, P2P is often not enough.\n\nTo solve this issue, WebRTC supports client/server topologies which, with the potential of being slightly slower, are not affected as much when a lot of clients interact. \n\n<div style=\"display: flex; justify-content: center;\">\n\t<div>\n\t    <img src='/images/uploads/06_10.png' description='SFU'>\n\t    <p style=\\\"margin-top:0px;font-size:12px;\\\">Selective Forward Unit (SFU)</p>\n\t</div>\n\t<div>\n\t    <img src='/images/uploads/06_11.png' description='MCU'>\n\t    <p style=\\\"margin-top:0px;font-size:12px;\\\">Multi-point Conferencing Unit (MCU 🦸‍♂️)</p>\n\t</div>\n</div>\n\n<br>\n\n### What if I like it raw?\n\nAlthough WebRTC is well known for media transmission, it can also be used to transmit raw data using a **DataChannel**.\n\nA DataChannel can handle any data and can be used to transmit raw media when specialized decoding methods are needed.\n\nEach peer can handle 65534 DataChannels, and they can be opened and closed at any time, as negotiation is not needed.\n\nThe other steps of the connection process are the same.\n```javascript\nconst peerConnection = new RTCPeerConnection(configurations);\n\n// establish connection\n\nconst dataChannel = pc.createDataChannel(\"channel1\");\n\ndataChannel.onMessage = (message) => { }\ndataChannel.onopen = () => { }\ndataChannel.onclose = () => { }\n\ndataChannel.send(\"hello there\");\n```\n\n<br>\n\n### And that's it\n\nAs I mentioned in the beginning, I started learning more about WebRTC because I wanted to build an application that benefits from all the goods offered by this protocol. \n\nIt's debatable if creating a new app for my specific use-case was justified, but I did it nonetheless. \n\nThis is how the app [*watchme*](https://github.com/devclub1/watchme) was built - it's open-source, so you can grab it, use it, modify it.\n\nLet me know what you think about it. \n\nI hope the not-so-deep-yet-still-pretty-deep dive that I did in this article was interesting, and, more important, useful. \n\nsee you next time :) \n\n*(the content of this article represents the core of the presentation that I did at Sibiu Web Meetup in January 2025 - if you're comfortable with Romanian, you can watch it [here](https://www.youtube.com/watch?v=dwVxXmYvwdc))*",
  "seoMetaImage": "/images/uploads/06_00.jpg",
  "seoDescription": "In the past two years, teaching has been one of the secondary activities I have been involved in the most. In a couple of ways. \nSome of them made me learn a bunch of new things. "
}